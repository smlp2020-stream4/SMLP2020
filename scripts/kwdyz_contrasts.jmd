---
Title: Contrast Coding of Visual Attention Effects
Author: Reinhold Kliegl
Date: 2020-09-10
---

```julia
using DrWatson
@quickactivate "SMLP2020"

using RCall 
using DataFrames, DataFramesMeta
using MixedModels
using Statistics: mean, std
using StatsModels: ContrastsCoding


#using StatsModels
#using LinearAlgebra, Statistics
```

## Example data

We take the `KWDYZ` dataset (Kliegl et al., 2011; Frontiers). This is an experiment looking at three effects of visual cueing under four different cue-target relations (CTRs). Two horizontal rectangles are displayed above and below a central fixation point or they displayed in vertical orientation to the left and right of the fixation point.  Subjects react to the onset of a small visual target occuring at one of the four ends of the two rectangles. The target is cued validly on 70% of trials by a brief flash of the corner of the rectangle at which it appears; it is cued invalidly at the three other locations 10% of the trials each. 

We specify three contrasts for the four-level factor CTR that are derived from spatial, object-based, and attractor-like features of attention. They map onto sequential differences between appropriately ordered factor levels. Interestingly, a different theoretical perspective, derived from feature overlap, leads to a different set of contrasts. Can the results refute one of the theoretical perspectives?

We also have a dataset from a replication and extension of this study (Kliegl, Kuschela, & Laubrock, 2015). Both data sets are available in [R-package RePsychLing](https://github.com/dmbates/RePsychLing/tree/master/data/) (Baayen et al., 2014).

```julia

# RCall
R"load($datadir('KWDYZ.rda'))";
dat1 = @rget KWDYZ;
dat1 = select(dat1, :subj => :Subj, :tar => :CTR, :rt);

# Set the factor levels
dat1 = @linq dat1 |>
        transform(CTR = levels!(categorical(:CTR), ["val", "sod", "dos", "dod"]));

first(dat1, 5)
describe(dat1)

# Descriptive statistics
cellmeans = by(dat1, [:CTR], 
            meanRT = :rt => mean, sdRT = :rt => std, n = :rt => length,
            semean = :rt => x -> std(x)/sqrt(length(x)))

OM = mean(dat1.rt)             # mean of observations
GM = mean(cellmeans.meanRT)    # grand mean = mean of conditions
```

## SeqDiffCoding 

This contrast corresponds to `MASS::contr.sdif()` in R.

```julia
cntr1 = Dict(
    :CTR  => SeqDiffCoding(levels=["val", "sod", "dos", "dod"]),
    :Subj => Grouping()
);


formula = @formula  rt ~ 1 + CTR + (1 + CTR | Subj)
m1 = fit(MixedModel, formula, dat1, contrasts=cntr1)

# Here is the general solution - manual hypothesis coding 
cntr1b = Dict(
    :CTR => HypothesisCoding([-1  1  0  0
                               0 -1  1  0
                               0  0 -1  1],
            levels=["val", "sod",  "dos", "dod"])
);

m1b = fit(MixedModel, formula, dat1, contrasts=cntr1b)

```

Controlling the ordering of levels for contrasts:

1.  kwarg `levels=` to order the levels; the first is set as the baseline.
2.  kwarg `base=` to fix the baseline level.

The assignment of random factors such as `Subj` to `Grouping()` is only necessary when the sample size is very large and leads to an out-of-memory error; it is included only in the first example for reference.

## DummyCoding 

This corresponds to `contr.treatment()` in R.

```julia
cntr2 = Dict(:CTR => DummyCoding(base= "val"));

m2 = fit(MixedModel, formula, dat1, contrasts=cntr2)
```

This contrast has the disadvantage that the intercept returns the mean of the level specified as `base`, default is the first level, not the GM. 

## YchycaeitCoding

The contrasts returned by `DummyCoding` may be what you want. Can't we have them, but also the GM rather than the mean of the base level?  Yes, we can!  I call this "You can have your cake and it eat, too"-Coding (YchycaeitCoding). 

```julia
cntr2b = Dict(
    :CTR => HypothesisCoding([-1  1  0  0
                              -1  0  1  0
                              -1  0  0  1],
            levels=["val", "sod",  "dos", "dod"])
);

m2b = fit(MixedModel, formula, dat1, contrasts=cntr2b)
```

Just relevel the factor or move the column with -1s for a different base.

## EffectsCoding 

This corresponds to `contr.sum()` in R.

```julia
cntr3 = Dict(:CTR => EffectsCoding(base= "dod"));

m3 = fit(MixedModel, formula, dat1, contrasts=cntr3)
```

## HelmertCoding 

```julia

cntr4 = Dict(:CTR => HelmertCoding());

fit(MixedModel, formula, dat1, contrasts=cntr4)

```

**Helmert contrasts that return the expected effect size**

```julia

man_helm2 = [-1    1    0   0
            -1/2 -1/2   1   0
            -1/3 -1/3 -1/3  1 ]

contr4b = Dict(:CTR => HypothesisCoding(man_helm2,
          levels=["sod", "val",  "dos", "dod"]));

fit(MixedModel, formula, dat1, contrasts=contr4b)

```

Helmert contrasts are othogonal.

## AnovaCoding

Anova contrasts are orthogonal.

### A(2) x B(2)

An A(2) x B(2) design can be recast as an F(4) design with the levels (A1-B1, A1-B2, A2-B1, A2-B2). The following contrast specifiction returns estimates for the main effect of A, the main effect of B, and the interaction of A and B. In a figure With A on the x-axis and the levels of B shown as two lines, the interaction tests the null hypothesis that the two lines are parallel. A positive coefficient implies overadditivity (diverging lines toward the right) and a negative coefficient underadditivity (converging lines).

```julia
cntr5 = Dict(
    :CTR => HypothesisCoding([-1  -1 +1  +1          # A
                              -1  +1 -1  +1          # B
                              +1  -1 -1  +1],        # A x B
            levels=["val", "sod",  "dos", "dod"])
);
m5 = fit(MixedModel, formula, dat1, contrasts=cntr5)
```

It is also helpful to see the corresponding layout of the four means for the interaction of A and B (i.e., the third contrast)

```
        B1     B2
   A1   +1     -1
   A2   -1     +1
   ```
   Thus, interaction tests whether the difference between main diagonal and minor diagonal is different from zero. 

### A(2) x B(2) x C(2)

Going beyond the four level factor. You can obtain this information with a few lines of code. 

```julia
R"""
df1 <- expand.grid(C=c("c1","c2"), B=c("b1","b2"), A = c("a1", "a2"))
contrasts(df1$A) <- contrasts(df1$B) <- contrasts(df1$C) <- contr.sum(2)
X <- model.matrix( ~ A*B*C, df1) # get design matrix for experiment
X_1 <- t(X[,2:8]) # transponse; we don't need the intercept column
"""

X_1 = @rget X_1;
cntr6 = Dict(:CTR => HypothesisCoding(X_1));
```
If you want subtract level 1 from level 2, multiply X with -1. I did not check whether the assignment of `X_1` in the last line really works. In any case you can use `X_1` as a starting point for explicit specification with `HypothesisCoding`.

It is also helpful to see the corresponding layout of the four means for the interaction of A and B (i.e., the third contrast)

```
          C1              C2
      B1     B2        B1     B2
 A1   +1     -1   A1   -1     +1
 A2   -1     +1   A2   +1     -1
 ```

### A(2) x B(2) x C(3)

For the three-level factor C we need to decide on a contrast. I am using the orthogonal Helmert contrast, because for non-orthogonal contrasts the correspondence between R and Julia breaks down. This is not a show-stopper, but requires 
a bit more coding. It is better to implement the following R chunk in Julia. 

```julia
R"""
df2 <- expand.grid( C=c("c1","c2","c3"),  B=c("b1","b2"), A = c("a1", "a2"))
contrasts(df2$A) <- contrasts(df2$B) <- contr.sum(2)
contrasts(df2$C) <- contr.helmert(3)

X <- model.matrix( ~ A*B*C, df2) # get design matrix for experiment
X_2 <- MASS::fractions(t(X[,2:12])) # transponse; we don't need the intercept column
"""

X_2 = @rget X_2;
cntr6 = Dict(:CTR => HypothesisCoding(X_2))
```
I have not checked whether the assignment of `X_2` really works. In any case you can use `X_2`as a starting point for explicit specification with `HypothesisCoding`.


## NestedCoding

An A(2) x B(2) design can be recast as an F(4) design with the levels (A1-B1, A1-B2, A2-B1, A2-B2).  The following contrast specifiction returns an estimate for the main effect of A and the effects of B nested in the two levels of A. In a figure With A on the x-axis and the levels of B shown as two lines, the second contrast tests whether A1-B1 is different from A1-B2 and the third contrast tests whether A2-B1 is different from A2-B2.

```julia
cntr7 = Dict(
    :CTR => HypothesisCoding([-1  -1 +1  +1          
                              -1  +1  0   0
                               0   0 -1  +1],
            levels=["val", "sod",  "dos", "dod"])
);
m7 = fit(MixedModel, formula, dat1, contrasts=cntr7)
```
The three contrasts for one main effect and two nested contrasts are orthogonal. There is no test of the interaction (parallelism).

## Other orthogonal contrasts

For factors with more than four levels there are many options for specifying orthogonal contrasts as long as one proceeds in a top-down strictly hiearchical fashion. 

Suppose you have a factor with seven levels and let's ignore shifting colummns. In this case, you have six options for the first contrast, that is 6 vs. 1, 5 vs.2 , 4 vs. 3, 3 vs. 4, 2 vs. 5, and 1 vs. 6 levels.  Then, you specify orthogonal contrasts for partitions with more than 2 elements and so on. That is, you don't specify a contrast that crosses an earlier partition line.  

In the following example, after an initial 4 vs 3 partitioning of levels, we specify `AnovaCoding` for the left and `HelmertCoding` for the right partition.

```julia
cntr8 = Dict(
    :CTR => HypothesisCoding(
    [-1/4 -1/4 -1/4 -1/4 +1/3 +1/3 +1/3          
     -1/2 -1/2 +1/2 +1/2   0    0    0
     -1/2 +1/2 -1/2 +1/2   0    0    0 
     +1/2 -1/2 -1/2 +1/2   0    0    0
       0    0    0    0   -1   +1    0
       0    0    0    0  -1/2 -1/2   1
     ])
);
```
There are two rules that hold for all orthogonal contrasts:

1. The weights within rows sum to zero.
2. For all pairs of rows, the sum of the products of weights in the same columns sums to zero. 


## Appendix: Summary (Dave Kleinschmidt)

[StatsModels](https://juliastats.org/StatsModels.jl/v0.2/contrasts.html)

StatsModels.jl provides a few commonly used contrast coding schemes,
some less-commonly used schemes, and structs that allow you to manually
specify your own, custom schemes. 

###### Standard contrasts

The most commonly used contrasts are `DummyCoding` and `EffectsCoding`
(which are similar to `contr.treatment()` and `contr.sum()` in R,
respectively).

###### "Exotic" contrasts (rk_comment: well ...)

We also provide `HelmertCoding` and `SeqDiffCoding` (corresponding to
base R's `contr.helmert()` and `MASS::contr.sdif()`).

###### Manual contrasts

**ContrastsCoding()**

There are two ways to manually specify contrasts. First, you can specify
them **directly** via `ContrastsCoding`. If you do, it's good practice
to specify the levels corresponding to the rows of the matrix, although
they can be omitted in which case they'll be inferred from the data.

**HypothesisCoding()**

A better way to specify manual contrasts is via `HypothesisCoding`, where each
row of the matrix corresponds to the weights given to the cell means of the
levels corresponding to each column (see [Schad et
al. 2020](https://doi.org/10.1016/j.jml.2019.104038) for more information). 

